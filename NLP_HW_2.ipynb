{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELnTtmB4KeLC",
        "outputId": "a32684d1-01e9-4dc3-ac0e-77366d6d7015"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cat:\n",
            "  Precision: 0.250\n",
            "  Recall:    0.250\n",
            "\n",
            "Dog:\n",
            "  Precision: 0.444\n",
            "  Recall:    0.444\n",
            "\n",
            "Rabbit:\n",
            "  Precision: 0.400\n",
            "  Recall:    0.400\n",
            "\n",
            "Macro-Averaged:\n",
            "  Precision: 0.365\n",
            "  Recall:    0.365\n",
            "\n",
            "Micro-Averaged:\n",
            "  Precision: 0.389\n",
            "  Recall:    0.389\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Confusion matrix (rows = predicted, columns = actual)\n",
        "cm = np.array([\n",
        "    [5, 10, 5],    # Predicted Cat\n",
        "    [15, 20, 10],  # Predicted Dog\n",
        "    [0, 15, 10]    # Predicted Rabbit\n",
        "])\n",
        "\n",
        "classes = [\"Cat\", \"Dog\", \"Rabbit\"]\n",
        "\n",
        "# Per-class precision and recall\n",
        "precisions = []\n",
        "recalls = []\n",
        "\n",
        "for i in range(len(classes)):\n",
        "    tp = cm[i, i]\n",
        "    predicted_total = np.sum(cm[i, :])   # row sum\n",
        "    actual_total = np.sum(cm[:, i])      # column sum\n",
        "\n",
        "    precision = tp / predicted_total\n",
        "    recall = tp / actual_total\n",
        "\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "\n",
        "    print(f\"{classes[i]}:\")\n",
        "    print(f\"  Precision: {precision:.3f}\")\n",
        "    print(f\"  Recall:    {recall:.3f}\")\n",
        "    print()\n",
        "\n",
        "# Macro averages\n",
        "macro_precision = np.mean(precisions)\n",
        "macro_recall = np.mean(recalls)\n",
        "\n",
        "# Micro averages\n",
        "total_tp = np.trace(cm)\n",
        "total_predictions = np.sum(cm)\n",
        "\n",
        "micro_precision = total_tp / total_predictions\n",
        "micro_recall = total_tp / total_predictions\n",
        "\n",
        "print(\"Macro-Averaged:\")\n",
        "print(f\"  Precision: {macro_precision:.3f}\")\n",
        "print(f\"  Recall:    {macro_recall:.3f}\")\n",
        "print()\n",
        "\n",
        "print(\"Micro-Averaged:\")\n",
        "print(f\"  Precision: {micro_precision:.3f}\")\n",
        "print(f\"  Recall:    {micro_recall:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "# 1️⃣ Training Corpus\n",
        "corpus = [\n",
        "    \"<s> I love NLP </s>\",\n",
        "    \"<s> I love deep learning </s>\",\n",
        "    \"<s> deep learning is fun </s>\"\n",
        "]\n",
        "\n",
        "# 2️⃣ Compute Unigram and Bigram Counts\n",
        "unigram_counts = defaultdict(int)\n",
        "bigram_counts = defaultdict(int)\n",
        "\n",
        "for sentence in corpus:\n",
        "    words = sentence.split()\n",
        "\n",
        "    # Count unigrams\n",
        "    for word in words:\n",
        "        unigram_counts[word] += 1\n",
        "\n",
        "    # Count bigrams\n",
        "    for i in range(len(words) - 1):\n",
        "        bigram = (words[i], words[i+1])\n",
        "        bigram_counts[bigram] += 1\n",
        "\n",
        "# 3️⃣ Estimate Bigram Probabilities (MLE)\n",
        "bigram_probs = {}\n",
        "\n",
        "for (w1, w2), count in bigram_counts.items():\n",
        "    bigram_probs[(w1, w2)] = count / unigram_counts[w1]\n",
        "\n",
        "# 4️⃣ Function to compute sentence probability\n",
        "def sentence_probability(sentence):\n",
        "    words = sentence.split()\n",
        "    prob = 1.0\n",
        "\n",
        "    for i in range(len(words) - 1):\n",
        "        bigram = (words[i], words[i+1])\n",
        "\n",
        "        if bigram in bigram_probs:\n",
        "            prob *= bigram_probs[bigram]\n",
        "        else:\n",
        "            # If unseen bigram, probability becomes 0\n",
        "            return 0.0\n",
        "\n",
        "    return prob\n",
        "\n",
        "# 5️⃣ Test Sentences\n",
        "s1 = \"<s> I love NLP </s>\"\n",
        "s2 = \"<s> I love deep learning </s>\"\n",
        "\n",
        "p1 = sentence_probability(s1)\n",
        "p2 = sentence_probability(s2)\n",
        "\n",
        "print(\"Sentence 1:\", s1)\n",
        "print(\"Probability:\", p1)\n",
        "print()\n",
        "\n",
        "print(\"Sentence 2:\", s2)\n",
        "print(\"Probability:\", p2)\n",
        "print()\n",
        "\n",
        "# 6️⃣ Compare\n",
        "if p1 > p2:\n",
        "    print(\"The model prefers Sentence 1.\")\n",
        "elif p2 > p1:\n",
        "    print(\"The model prefers Sentence 2.\")\n",
        "else:\n",
        "    print(\"Both sentences are equally probable.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9MdTUTkLopD",
        "outputId": "ba697d45-3cba-45f1-f7c1-bd3a4062be5b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence 1: <s> I love NLP </s>\n",
            "Probability: 0.3333333333333333\n",
            "\n",
            "Sentence 2: <s> I love deep learning </s>\n",
            "Probability: 0.16666666666666666\n",
            "\n",
            "The model prefers Sentence 1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PlCse6O3LtPW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}